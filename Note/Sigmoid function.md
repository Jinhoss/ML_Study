# Sigmoid function

단순 선형 회귀분석은 목표가 실수값 예측이기 때문에 선형함수 y = wx + b를 이용하여 예측한다. 하지만 로지스틱 회귀분석처럼 이진분류의 경우에는 종속변수가 0 또는 1이기 때문에 y = wx + b를 이용해서 예측하는 것은 의미가 없다.

그래서 Odds를 이용하는데 Odds는 다음과 같이 정의된다. 확률 p가 주어져 있을 때 

![sigmoid1](C:\Users\Jinho\Desktop\sigmoid1.PNG)

로 정의한다. 확률값 p는 공리에 따라 값의 범위가 0~1이기 때문에 Odds(p)의 범위는 0~무한대가 된다. 여기에 로그함수를 취한 log(Odds(p))는 음의 무한대~ 무한대, 즉 실수 전체가 된다. log(Odds(p))의 범위가 실수이므로 이 값에 대해 선형 회귀분석을 하는 것은 의미가 있다.



따라서, log(Odds(p)) = wx + b로 선형 회귀분석을 하면 w와 b값을 얻을 수 있게 되고 이를 확률 p로 정리하게 되면



![sigmoid2](C:\Users\Jinho\Desktop\sigmoid2.PNG)

과 같은 식을 얻을 수 있다.



- 최근에 사용하지 않는 이유

  - **Gradient Vanishing** 현상이 발생한다. 미분함수에 대해 x=0x=0에서 최대값 1414 을 가지고, input값이 일정이상 올라가면 미분값이 거의 0에 수렴하게된다. 이는 |x|값이 커질 수록 Gradient Backpropagation시 미분값이 소실될 가능성이 크다.

  - **함수값 중심이 0이 아니다.** 함수값 중심이 0이 아니라 학습이 느려질 수 있다.

  - exp 함수 사용시 비용이 크다.

     

